<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>äººå·¥æ™ºèƒ½ | Automation & Industrial Control Technician</title><meta name=keywords content><meta name=description content="ä¸“ä¸šçš„è‡ªåŠ¨åŒ–ä¸å·¥ä¸šæ§åˆ¶æŠ€æœ¯å‘˜ | PLCç¼–ç¨‹ | åµŒå…¥å¼æ§åˆ¶ | SolidWorksè®¾è®¡"><meta name=author content="dmk69"><link rel=canonical href=https://hugo-maker-blog.vercel.app/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://hugo-maker-blog.vercel.app/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://hugo-maker-blog.vercel.app/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://hugo-maker-blog.vercel.app/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://hugo-maker-blog.vercel.app/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://hugo-maker-blog.vercel.app/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://hugo-maker-blog.vercel.app/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml title=rss><link rel=alternate hreflang=en href=https://hugo-maker-blog.vercel.app/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://hugo-maker-blog.vercel.app/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"><meta property="og:site_name" content="Automation & Industrial Control Technician"><meta property="og:title" content="äººå·¥æ™ºèƒ½"><meta property="og:description" content="ä¸“ä¸šçš„è‡ªåŠ¨åŒ–ä¸å·¥ä¸šæ§åˆ¶æŠ€æœ¯å‘˜ | PLCç¼–ç¨‹ | åµŒå…¥å¼æ§åˆ¶ | SolidWorksè®¾è®¡"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta property="og:image" content="https://hugo-maker-blog.vercel.app/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://hugo-maker-blog.vercel.app/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="äººå·¥æ™ºèƒ½"><meta name=twitter:description content="ä¸“ä¸šçš„è‡ªåŠ¨åŒ–ä¸å·¥ä¸šæ§åˆ¶æŠ€æœ¯å‘˜ | PLCç¼–ç¨‹ | åµŒå…¥å¼æ§åˆ¶ | SolidWorksè®¾è®¡"></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://hugo-maker-blog.vercel.app/ accesskey=h title="Home (Alt + H)"><img src=https://hugo-maker-blog.vercel.app/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://hugo-maker-blog.vercel.app/projects/ title=é¡¹ç›®å±•ç¤º><span>é¡¹ç›®å±•ç¤º</span></a></li><li><a href=https://hugo-maker-blog.vercel.app/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://hugo-maker-blog.vercel.app/tags/ title=æ ‡ç­¾><span>æ ‡ç­¾</span></a></li><li><a href=https://hugo-maker-blog.vercel.app/about/ title=å…³äº><span>å…³äº</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://hugo-maker-blog.vercel.app/>Home</a>&nbsp;Â»&nbsp;<a href=https://hugo-maker-blog.vercel.app/tags/>Tags</a></div><h1>äººå·¥æ™ºèƒ½
<a href=/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy src="https://images.unsplash.com/photo-1555949963-aa79dcee981c?w=800&amp;h=400&amp;fit=crop" alt="AI Machine Learning"></figure><header class=entry-header><h2 class=entry-hint-parent>Python AIå®Œå…¨å­¦ä¹ è·¯å¾„ï¼šä»é›¶åŸºç¡€åˆ°æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ</h2></header><div class=entry-content><p>ğŸ¤– Python AIå®Œå…¨å­¦ä¹ è·¯å¾„ï¼šä»é›¶åŸºç¡€åˆ°æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ Pythonæ˜¯äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ é¢†åŸŸæœ€å—æ¬¢è¿çš„ç¼–ç¨‹è¯­è¨€ã€‚æœ¬å­¦ä¹ è·¯å¾„å°†å¸¦ä½ ä»PythonåŸºç¡€å¼€å§‹ï¼Œé€æ­¥æˆé•¿ä¸ºä¸€ååˆæ ¼çš„AIå·¥ç¨‹å¸ˆã€‚
ğŸ“‹ å­¦ä¹ è·¯çº¿å›¾ PythonåŸºç¡€ â†’ æ•°æ®åˆ†æ â†’ æœºå™¨å­¦ä¹  â†’ æ·±åº¦å­¦ä¹  â†’ ä¸“ä¸šæ–¹å‘ â†“ â†“ â†“ â†“ â†“ 3ä¸ªæœˆ 2ä¸ªæœˆ 3ä¸ªæœˆ 3ä¸ªæœˆ 4ä¸ªæœˆ ğŸ ç¬¬ä¸€é˜¶æ®µï¼šPythonç¼–ç¨‹åŸºç¡€ (1-3ä¸ªæœˆ) 1.1 PythonåŸºç¡€è¯­æ³• å˜é‡å’Œæ•°æ®ç±»å‹ # åŸºç¡€æ•°æ®ç±»å‹ name = "å¼ ä¸‰" # å­—ç¬¦ä¸² age = 25 # æ•´æ•° height = 175.5 # æµ®ç‚¹æ•° is_student = True # å¸ƒå°”å€¼ grades = [90, 85, 78] # åˆ—è¡¨ profile = {"name": "æå››", "age": 30} # å­—å…¸ # ç±»å‹è½¬æ¢ age_str = str(age) height_int = int(height) æ§åˆ¶æµç¨‹ # æ¡ä»¶è¯­å¥ if age >= 18: print("æˆå¹´äºº") elif age >= 13: print("é’å°‘å¹´") else: print("å„¿ç«¥") # å¾ªç¯è¯­å¥ for i in range(5): print(f"ç¬¬{i+1}æ¬¡å¾ªç¯") while age &lt; 65: age += 1 print(f"å¹´é¾„å¢é•¿åˆ°{age}å²") å‡½æ•°å®šä¹‰ def calculate_bmi(weight, height): """è®¡ç®—BMIæŒ‡æ•°""" bmi = weight / (height ** 2) if bmi &lt; 18.5: category = "åç˜¦" elif bmi &lt; 24: category = "æ­£å¸¸" else: category = "åèƒ–" return round(bmi, 2), category # ä½¿ç”¨å‡½æ•° bmi, category = calculate_bmi(70, 1.75) print(f"BMI: {bmi}, ä½“å‹: {category}") 1.2 é¢å‘å¯¹è±¡ç¼–ç¨‹ ç±»å’Œå¯¹è±¡ class Student: def __init__(self, name, student_id): self.name = name self.student_id = student_id self.grades = [] def add_grade(self, grade): self.grades.append(grade) def get_average(self): return sum(self.grades) / len(self.grades) def __str__(self): return f"å­¦ç”Ÿ: {self.name}, å­¦å·: {self.student_id}" # åˆ›å»ºå¯¹è±¡ student1 = Student("ç‹äº”", "2021001") student1.add_grade(90) student1.add_grade(85) print(student1) print(f"å¹³å‡åˆ†: {student1.get_average()}") 1.3 æ–‡ä»¶æ“ä½œå’Œå¼‚å¸¸å¤„ç† # æ–‡ä»¶è¯»å†™ def save_student_data(students, filename): try: with open(filename, 'w', encoding='utf-8') as f: for student in students: f.write(f"{student.name},{student.student_id},{student.get_average()}\n") print("æ•°æ®ä¿å­˜æˆåŠŸ") except IOError as e: print(f"æ–‡ä»¶æ“ä½œé”™è¯¯: {e}") def load_student_data(filename): students = [] try: with open(filename, 'r', encoding='utf-8') as f: for line in f: name, student_id, avg_grade = line.strip().split(',') print(f"å­¦ç”Ÿ: {name}, å¹³å‡åˆ†: {avg_grade}") except FileNotFoundError: print("æ–‡ä»¶ä¸å­˜åœ¨") return students ğŸ“Š ç¬¬äºŒé˜¶æ®µï¼šæ•°æ®åˆ†æåŸºç¡€ (2ä¸ªæœˆ) 2.1 NumPyæ•°å€¼è®¡ç®— æ•°ç»„æ“ä½œ import numpy as np # åˆ›å»ºæ•°ç»„ arr1 = np.array([1, 2, 3, 4, 5]) arr2 = np.random.randn(3, 3) # 3x3éšæœºæ•°ç»„ arr3 = np.zeros((5, 5)) # 5x5é›¶æ•°ç»„ arr4 = np.ones((2, 3)) # 2x3å•ä½æ•°ç»„ # æ•°ç»„è¿ç®— result = arr1 + 10 # æ•°ç»„ä¸æ ‡é‡è¿ç®— dot_product = np.dot(arr1, arr1) # ç‚¹ç§¯ # çŸ©é˜µæ“ä½œ matrix = np.array([[1, 2], [3, 4]]) transpose = matrix.T # è½¬ç½® inverse = np.linalg.inv(matrix) # é€†çŸ©é˜µ ç»Ÿè®¡åˆ†æ # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® data = np.random.normal(100, 15, 1000) # æ­£æ€åˆ†å¸ƒ # ç»Ÿè®¡åˆ†æ mean = np.mean(data) # å‡å€¼ median = np.median(data) # ä¸­ä½æ•° std = np.std(data) # æ ‡å‡†å·® percentiles = np.percentile(data, [25, 50, 75]) # å››åˆ†ä½æ•° print(f"å‡å€¼: {mean:.2f}") print(f"æ ‡å‡†å·®: {std:.2f}") print(f"å››åˆ†ä½æ•°: {percentiles}") 2.2 Pandasæ•°æ®å¤„ç† DataFrameæ“ä½œ import pandas as pd # åˆ›å»ºDataFrame data = { 'å§“å': ['å¼ ä¸‰', 'æå››', 'ç‹äº”', 'èµµå…­'], 'å¹´é¾„': [25, 30, 35, 28], 'åŸå¸‚': ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³'], 'è–ªèµ„': [15000, 20000, 18000, 22000] } df = pd.DataFrame(data) # æ•°æ®ç­›é€‰ high_salary = df[df['è–ªèµ„'] > 18000] # è–ªèµ„å¤§äº18000çš„å‘˜å·¥ beijing_employees = df[df['åŸå¸‚'] == 'åŒ—äº¬'] # åŒ—äº¬å‘˜å·¥ # æ•°æ®èšåˆ city_avg_salary = df.groupby('åŸå¸‚')['è–ªèµ„'].mean() age_stats = df['å¹´é¾„'].describe() print("åŸå¸‚å¹³å‡è–ªèµ„:") print(city_avg_salary) æ•°æ®å¤„ç† # è¯»å–CSVæ–‡ä»¶ df = pd.read_csv('sales_data.csv') # æ•°æ®æ¸…æ´— # å¤„ç†ç¼ºå¤±å€¼ df.dropna(inplace=True) # åˆ é™¤ç¼ºå¤±å€¼ df.fillna(0, inplace=True) # å¡«å……ç¼ºå¤±å€¼ # å¤„ç†é‡å¤å€¼ df.drop_duplicates(inplace=True) # æ•°æ®è½¬æ¢ df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ']) # è½¬æ¢æ—¥æœŸæ ¼å¼ df['å¹´ä»½'] = df['æ—¥æœŸ'].dt.year # æå–å¹´ä»½ # æ•°æ®åˆ†æ monthly_sales = df.groupby('å¹´ä»½')['é”€å”®é¢'].sum() best_month = monthly_sales.idxmax() 2.3 Matplotlibæ•°æ®å¯è§†åŒ– åŸºç¡€å›¾è¡¨ import matplotlib.pyplot as plt import numpy as np # è®¾ç½®ä¸­æ–‡å­—ä½“ plt.rcParams['font.sans-serif'] = ['SimHei'] plt.rcParams['axes.unicode_minus'] = False # ç”Ÿæˆæ•°æ® months = ['1æœˆ', '2æœˆ', '3æœˆ', '4æœˆ', '5æœˆ', '6æœˆ'] sales = [120, 150, 180, 160, 200, 240] profits = [30, 45, 60, 50, 80, 95] # åˆ›å»ºå›¾è¡¨ fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5)) # æŠ˜çº¿å›¾ ax1.plot(months, sales, marker='o', linewidth=2, label='é”€å”®é¢') ax1.plot(months, profits, marker='s', linewidth=2, label='åˆ©æ¶¦') ax1.set_title('æœˆåº¦é”€å”®è¶‹åŠ¿') ax1.set_xlabel('æœˆä»½') ax1.set_ylabel('é‡‘é¢(ä¸‡å…ƒ)') ax1.legend() ax1.grid(True) # æŸ±çŠ¶å›¾ ax2.bar(months, sales, alpha=0.7, color='skyblue') ax2.set_title('æœˆåº¦é”€å”®é¢') ax2.set_xlabel('æœˆä»½') ax2.set_ylabel('é”€å”®é¢(ä¸‡å…ƒ)') plt.tight_layout() plt.show() ğŸ¤– ç¬¬ä¸‰é˜¶æ®µï¼šæœºå™¨å­¦ä¹ å…¥é—¨ (3ä¸ªæœˆ) 3.1 ç›‘ç£å­¦ä¹ åŸºç¡€ çº¿æ€§å›å½’ from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error, r2_score import numpy as np # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ® np.random.seed(42) X = np.random.rand(100, 1) * 10 # ç‰¹å¾ y = 2 * X + 1 + np.random.randn(100, 1) * 2 # ç›®æ ‡å€¼ # æ•°æ®åˆ†å‰² X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=42 ) # åˆ›å»ºæ¨¡å‹ model = LinearRegression() model.fit(X_train, y_train) # é¢„æµ‹ y_pred = model.predict(X_test) # è¯„ä¼° mse = mean_squared_error(y_test, y_pred) r2 = r2_score(y_test, y_pred) print(f"æ¨¡å‹å‚æ•°: æ–œç‡={model.coef_[0][0]:.2f}, æˆªè·={model.intercept_[0]:.2f}") print(f"å‡æ–¹è¯¯å·®: {mse:.2f}") print(f"RÂ²åˆ†æ•°: {r2:.2f}") é€»è¾‘å›å½’ from sklearn.linear_model import LogisticRegression from sklearn.datasets import make_classification from sklearn.metrics import accuracy_score, confusion_matrix # ç”Ÿæˆåˆ†ç±»æ•°æ® X, y = make_classification( n_samples=1000, n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=1, random_state=42 ) # æ•°æ®åˆ†å‰² X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42 ) # åˆ›å»ºæ¨¡å‹ model = LogisticRegression() model.fit(X_train, y_train) # é¢„æµ‹ y_pred = model.predict(X_test) # è¯„ä¼° accuracy = accuracy_score(y_test, y_pred) conf_matrix = confusion_matrix(y_test, y_pred) print(f"å‡†ç¡®ç‡: {accuracy:.2f}") print("æ··æ·†çŸ©é˜µ:") print(conf_matrix) 3.2 å†³ç­–æ ‘å’Œéšæœºæ£®æ— å†³ç­–æ ‘åˆ†ç±» from sklearn.tree import DecisionTreeClassifier from sklearn import tree import matplotlib.pyplot as plt # åˆ›å»ºå†³ç­–æ ‘æ¨¡å‹ dt_model = DecisionTreeClassifier(max_depth=3, random_state=42) dt_model.fit(X_train, y_train) # é¢„æµ‹ y_pred_dt = dt_model.predict(X_test) accuracy_dt = accuracy_score(y_test, y_pred_dt) print(f"å†³ç­–æ ‘å‡†ç¡®ç‡: {accuracy_dt:.2f}") # å¯è§†åŒ–å†³ç­–æ ‘ plt.figure(figsize=(15, 10)) tree.plot_tree(dt_model, feature_names=['ç‰¹å¾1', 'ç‰¹å¾2'], class_names=['ç±»åˆ«0', 'ç±»åˆ«1'], filled=True) plt.show() éšæœºæ£®æ— from sklearn.ensemble import RandomForestClassifier # åˆ›å»ºéšæœºæ£®æ—æ¨¡å‹ rf_model = RandomForestClassifier( n_estimators=100, max_depth=5, random_state=42 ) rf_model.fit(X_train, y_train) # ç‰¹å¾é‡è¦æ€§ feature_importance = rf_model.feature_importances_ print(f"ç‰¹å¾é‡è¦æ€§: {feature_importance}") # é¢„æµ‹ y_pred_rf = rf_model.predict(X_test) accuracy_rf = accuracy_score(y_test, y_pred_rf) print(f"éšæœºæ£®æ—å‡†ç¡®ç‡: {accuracy_rf:.2f}") 3.3 æ¨¡å‹è¯„ä¼°å’Œè°ƒä¼˜ äº¤å‰éªŒè¯ from sklearn.model_selection import cross_val_score, GridSearchCV # äº¤å‰éªŒè¯ scores = cross_val_score(rf_model, X, y, cv=5) print(f"äº¤å‰éªŒè¯åˆ†æ•°: {scores}") print(f"å¹³å‡å‡†ç¡®ç‡: {scores.mean():.2f} (Â±{scores.std():.2f})") # ç½‘æ ¼æœç´¢è°ƒä¼˜ param_grid = { 'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7, None], 'min_samples_split': [2, 5, 10] } grid_search = GridSearchCV( RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy' ) grid_search.fit(X_train, y_train) print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}") print(f"æœ€ä½³åˆ†æ•°: {grid_search.best_score_:.2f}") ğŸ§  ç¬¬å››é˜¶æ®µï¼šæ·±åº¦å­¦ä¹  (3ä¸ªæœˆ) 4.1 ç¥ç»ç½‘ç»œåŸºç¡€ ä½¿ç”¨TensorFlow/Keras import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers # åˆ›å»ºç®€å•çš„ç¥ç»ç½‘ç»œ model = keras.Sequential([ layers.Dense(64, activation='relu', input_shape=(2,)), layers.Dense(32, activation='relu'), layers.Dense(1, activation='sigmoid') ]) # ç¼–è¯‘æ¨¡å‹ model.compile( optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'] ) # æ¨¡å‹æ‘˜è¦ model.summary() # è®­ç»ƒæ¨¡å‹ history = model.fit( X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1 ) # è¯„ä¼°æ¨¡å‹ test_loss, test_accuracy = model.evaluate(X_test, y_test) print(f"æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy:.2f}") æ·±åº¦å­¦ä¹ é¡¹ç›®ï¼šå›¾åƒåˆ†ç±» from tensorflow.keras.preprocessing.image import ImageDataGenerator from tensorflow.keras.applications import VGG16 # æ•°æ®å¢å¼º train_datagen = ImageDataGenerator( rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, validation_split=0.2 ) # æ•°æ®åŠ è½½ train_generator = train_datagen.flow_from_directory( 'data/images', target_size=(224, 224), batch_size=32, class_mode='binary', subset='training' ) # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) # å†»ç»“é¢„è®­ç»ƒå±‚ for layer in base_model.layers: layer.trainable = False # æ·»åŠ è‡ªå®šä¹‰å±‚ model = keras.Sequential([ base_model, layers.Flatten(), layers.Dense(256, activation='relu'), layers.Dropout(0.5), layers.Dense(1, activation='sigmoid') ]) model.compile( optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'] ) 4.2 è‡ªç„¶è¯­è¨€å¤„ç† æ–‡æœ¬åˆ†ç±» from tensorflow.keras.preprocessing.text import Tokenizer from tensorflow.keras.preprocessing.sequence import pad_sequences # æ–‡æœ¬é¢„å¤„ç† texts = [ "è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨", "æœåŠ¡æ€åº¦å¾ˆå·®", "ç‰©æµé€Ÿåº¦å¾ˆå¿«", "è´¨é‡æœ‰é—®é¢˜" ] labels = [1, 0, 1, 0] # 1:æ­£é¢, 0:è´Ÿé¢ # åˆ†è¯å’Œç¼–ç  tokenizer = Tokenizer(num_words=1000) tokenizer.fit_on_texts(texts) sequences = tokenizer.texts_to_sequences(texts) # åºåˆ—å¡«å…… max_length = 10 padded_sequences = pad_sequences(sequences, maxlen=max_length) # æ„å»ºæ–‡æœ¬åˆ†ç±»æ¨¡å‹ model = keras.Sequential([ layers.Embedding(1000, 16, input_length=max_length), layers.LSTM(32), layers.Dense(16, activation='relu'), layers.Dense(1, activation='sigmoid') ]) model.compile( optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'] ) ğŸ¯ ç¬¬äº”é˜¶æ®µï¼šä¸“ä¸šæ–¹å‘é€‰æ‹© (4ä¸ªæœˆ) 5.1 è®¡ç®—æœºè§†è§‰æ–¹å‘ ç›®æ ‡æ£€æµ‹é¡¹ç›® import cv2 import numpy as np # ä½¿ç”¨OpenCVè¿›è¡Œç›®æ ‡æ£€æµ‹ def detect_objects(image_path): # è¯»å–å›¾åƒ image = cv2.imread(image_path) # è½¬æ¢ä¸ºç°åº¦å›¾ gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # ä½¿ç”¨Haarçº§è”åˆ†ç±»å™¨æ£€æµ‹äººè„¸ face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') faces = face_cascade.detectMultiScale(gray, 1.1, 4) # ç»˜åˆ¶æ£€æµ‹æ¡† for (x, y, w, h) in faces: cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2) return image # æ˜¾ç¤ºç»“æœ result_image = detect_objects('test_image.jpg') cv2.imshow('Object Detection', result_image) cv2.waitKey(0) cv2.destroyAllWindows() 5.2 è‡ªç„¶è¯­è¨€å¤„ç†æ–¹å‘ æƒ…æ„Ÿåˆ†æç³»ç»Ÿ from transformers import pipeline # ä½¿ç”¨é¢„è®­ç»ƒçš„æƒ…æ„Ÿåˆ†ææ¨¡å‹ classifier = pipeline("sentiment-analysis") def analyze_sentiment(text): result = classifier(text)[0] sentiment = result['label'] confidence = result['score'] return { 'sentiment': sentiment, 'confidence': confidence, 'text': text } # æ‰¹é‡åˆ†æ comments = [ "è¿™å®¶é¤å…çš„é£Ÿç‰©å¾ˆç¾å‘³", "ç­‰å¾…æ—¶é—´å¤ªé•¿äº†", "æœåŠ¡æ€åº¦å¾ˆå¥½ï¼Œç¯å¢ƒä¹Ÿä¸é”™" ] for comment in comments: result = analyze_sentiment(comment) print(f"æ–‡æœ¬: {comment}") print(f"æƒ…æ„Ÿ: {result['sentiment']}") print(f"ç½®ä¿¡åº¦: {result['confidence']:.2f}") print("-" * 50) 5.3 å¼ºåŒ–å­¦ä¹ æ–¹å‘ Q-Learningç®—æ³•å®ç° import numpy as np class QLearningAgent: def __init__(self, state_size, action_size, learning_rate=0.1, discount_factor=0.95): self.state_size = state_size self.action_size = action_size self.learning_rate = learning_rate self.discount_factor = discount_factor self.epsilon = 1.0 # æ¢ç´¢ç‡ self.epsilon_min = 0.01 self.epsilon_decay = 0.995 self.q_table = np.zeros((state_size, action_size)) def choose_action(self, state): if np.random.random() &lt;= self.epsilon: return np.random.randint(self.action_size) else: return np.argmax(self.q_table[state]) def learn(self, state, action, reward, next_state): current_q = self.q_table[state, action] max_next_q = np.max(self.q_table[next_state]) new_q = current_q + self.learning_rate * ( reward + self.discount_factor * max_next_q - current_q ) self.q_table[state, action] = new_q if self.epsilon > self.epsilon_min: self.epsilon *= self.epsilon_decay # è®­ç»ƒæ™ºèƒ½ä½“ agent = QLearningAgent(state_size=16, action_size=4) episodes = 1000 for episode in range(episodes): state = 0 # åˆå§‹çŠ¶æ€ done = False while not done: action = agent.choose_action(state) reward, next_state, done = environment_step(state, action) agent.learn(state, action, reward, next_state) state = next_state ğŸ“ˆ å­¦ä¹ æ—¶é—´è§„åˆ’ åŸºç¡€é˜¶æ®µ (å‰3ä¸ªæœˆ) ç¬¬1ä¸ªæœˆ: PythonåŸºç¡€è¯­æ³•å’Œæ•°æ®ç»“æ„ ç¬¬2ä¸ªæœˆ: é¢å‘å¯¹è±¡ç¼–ç¨‹å’Œæ–‡ä»¶æ“ä½œ ç¬¬3ä¸ªæœˆ: å¸¸ç”¨åº“ä½¿ç”¨å’Œå°é¡¹ç›®å®è·µ æ•°æ®åˆ†æé˜¶æ®µ (ç¬¬4-5ä¸ªæœˆ) ç¬¬4ä¸ªæœˆ: NumPyå’ŒPandasæ·±å…¥å­¦ä¹  ç¬¬5ä¸ªæœˆ: æ•°æ®å¯è§†åŒ–å’Œå°å‹æ•°æ®åˆ†æé¡¹ç›® æœºå™¨å­¦ä¹ é˜¶æ®µ (ç¬¬6-8ä¸ªæœˆ) ç¬¬6ä¸ªæœˆ: ç›‘ç£å­¦ä¹ ç®—æ³•å’Œæ¨¡å‹è¯„ä¼° ç¬¬7ä¸ªæœˆ: é›†æˆå­¦ä¹ å’Œç‰¹å¾å·¥ç¨‹ ç¬¬8ä¸ªæœˆ: å®Œæ•´çš„æœºå™¨å­¦ä¹ é¡¹ç›® æ·±åº¦å­¦ä¹ é˜¶æ®µ (ç¬¬9-11ä¸ªæœˆ) ç¬¬9ä¸ªæœˆ: ç¥ç»ç½‘ç»œåŸºç¡€å’ŒTensorFlow ç¬¬10ä¸ªæœˆ: CNNå’Œå›¾åƒå¤„ç† ç¬¬11ä¸ªæœˆ: RNNå’Œè‡ªç„¶è¯­è¨€å¤„ç† ä¸“ä¸šæ–¹å‘é˜¶æ®µ (ç¬¬12-15ä¸ªæœˆ) ç¬¬12-15ä¸ªæœˆ: é€‰æ‹©ä¸“ä¸šæ–¹å‘å¹¶æ·±å…¥å®è·µ ğŸ› ï¸ å®è·µé¡¹ç›®å»ºè®® åˆçº§é¡¹ç›® (1-3ä¸ªæœˆ) ä¸ªäººè´¢åŠ¡ç®¡ç†ç³»ç»Ÿ: ä½¿ç”¨Pandasåˆ†ææ”¶æ”¯æ•°æ® å¤©æ°”æ•°æ®å¯è§†åŒ–: æŠ“å–å¤©æ°”æ•°æ®å¹¶åˆ¶ä½œå›¾è¡¨ ç®€å•è®¡ç®—å™¨: Python GUIåº”ç”¨å¼€å‘ ä¸­çº§é¡¹ç›® (4-8ä¸ªæœˆ) æˆ¿ä»·é¢„æµ‹ç³»ç»Ÿ: çº¿æ€§å›å½’å’Œå¤šé¡¹å¼å›å½’ å®¢æˆ·æµå¤±é¢„æµ‹: é€»è¾‘å›å½’å’Œå†³ç­–æ ‘ å›¾ä¹¦æ¨èç³»ç»Ÿ: ååŒè¿‡æ»¤ç®—æ³• é«˜çº§é¡¹ç›® (9-12ä¸ªæœˆ) å›¾åƒåˆ†ç±»åº”ç”¨: æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ¨ç½² èŠå¤©æœºå™¨äºº: NLPå’Œå¯¹è¯ç³»ç»Ÿ è‚¡ç¥¨ä»·æ ¼é¢„æµ‹: æ—¶é—´åºåˆ—åˆ†æ ğŸ’¡ å­¦ä¹ å»ºè®® 1. ç†è®ºä¸å®è·µç»“åˆ æ¯å­¦å®Œä¸€ä¸ªæ¦‚å¿µï¼Œç«‹å³ç¼–å†™ä»£ç å®è·µ å‚ä¸Kaggleç«èµ›æå‡å®æˆ˜èƒ½åŠ› é˜…è¯»ç»å…¸è®ºæ–‡äº†è§£ç®—æ³•åŸç† 2. å»ºç«‹é¡¹ç›®ä½œå“é›† æ¯ä¸ªæœˆå®Œæˆä¸€ä¸ªå®Œæ•´é¡¹ç›® å°†é¡¹ç›®éƒ¨ç½²åˆ°GitHubæˆ–ä¸ªäººç½‘ç«™ ç¼–å†™è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£ 3. æŒç»­å­¦ä¹  å…³æ³¨AIé¢†åŸŸæœ€æ–°å‘å±• å‚åŠ æŠ€æœ¯meetupå’Œä¼šè®® åŠ å…¥AIå­¦ä¹ ç¤¾åŒº 4. æ•°å­¦åŸºç¡€ çº¿æ€§ä»£æ•°: çŸ©é˜µè¿ç®—ã€ç‰¹å¾å€¼ æ¦‚ç‡ç»Ÿè®¡: æ¦‚ç‡åˆ†å¸ƒã€å‡è®¾æ£€éªŒ å¾®ç§¯åˆ†: å¯¼æ•°ã€æ¢¯åº¦ä¸‹é™ ğŸ“š æ¨èèµ„æº åœ¨çº¿è¯¾ç¨‹ Coursera: Andrew Ngçš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ Udacity: AIçº³ç±³å­¦ä½ edX: MITçš„è®¡ç®—æœºç§‘å­¦è¯¾ç¨‹ ä¹¦ç±æ¨è ã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹ ã€Šæœºå™¨å­¦ä¹ å®æˆ˜ã€‹ ã€Šæ·±åº¦å­¦ä¹ ã€‹- Ian Goodfellow å¼€æºé¡¹ç›® Scikit-learn: æœºå™¨å­¦ä¹ åº“ TensorFlow: æ·±åº¦å­¦ä¹ æ¡†æ¶ Fast.ai: æ·±åº¦å­¦ä¹ æœ€ä½³å®è·µ AIå­¦ä¹ æ˜¯ä¸€ä¸ªé•¿æœŸçš„è¿‡ç¨‹ï¼Œéœ€è¦æŒç»­å­¦ä¹ å’Œå®è·µã€‚å¸Œæœ›è¿™ä¸ªå­¦ä¹ è·¯å¾„èƒ½å¸®åŠ©ä½ ä»é›¶åŸºç¡€æˆé•¿ä¸ºAIå·¥ç¨‹å¸ˆï¼
...</p></div><footer class=entry-footer><span title='2025-11-08 11:30:00 +0800 CST'>2025-11-08</span>&nbsp;Â·&nbsp;<span>7 min</span>&nbsp;Â·&nbsp;<span>1406 words</span>&nbsp;Â·&nbsp;<span>dmk69</span></footer><a class=entry-link aria-label="post link to Python AIå®Œå…¨å­¦ä¹ è·¯å¾„ï¼šä»é›¶åŸºç¡€åˆ°æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ" href=https://hugo-maker-blog.vercel.app/posts/python-ai-learning-path/></a></article></main><footer class=footer><span>&copy; 2025 <a href=https://hugo-maker-blog.vercel.app/>Automation & Industrial Control Technician</a></span> Â·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>